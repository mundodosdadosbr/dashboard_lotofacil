Cenário:

Coloquei no diretório do AST /ROH-RECEBIVEIS_OPERADOR_HOM/ENTRADA/ o arquivo ROH.M0241.20240119164911.R.ROH.M0241.123424.L3303.2024011911330100.LSH00146.arquivo_no_lugar_das_pastas.zip (https://sa-east-1.console.aws.amazon.com/s3/object/datahub-comportamental-input-dev?region=sa-east-1&bucketType=general&prefix=qa/cerc/teste_gui/operador_optout/ROH.M0241.20240119164911.R.ROH.M0241.123424.L3303.2024011911330100.LSH00146.arquivo_no_lugar_das_pastas.zip )
Esse arquivo .zip, não tem no seu interior as estruturas de pastas esperadas. Ele tem apenas arquivos parquets contendo o mesmo nome esperados das pastas que estão ausentes.
Esse arquivo usado como massa de entrada do processo foi anexado a esse defeito também.
 
Execute a DAG experian_datahub_cerc_app_operador_optout.
Vá analisando a log do arquivo stderr do EMR relacionado a execução da DAG.
Resultado Atual:

O processamento identifica um erro relacionado ao HDFS (como esperado), loga o erro no arquivo de log stderr mas continua a execução do processo. Não estamos falhando a DAG na hora que ocorre esse erro do HDFS e nem parando a execução do processamento depois desse ponto:
2024-06-11 19:14:00 (133 MB/s) - â€˜experian-datahub-knarr-0.0.11.jarâ€™ saved [510460918/510460918]

/home/hadoop/.local/lib/python3.7/site-packages/pysftp/__init__.py:61: UserWarning: Failed to load HostKeys from /home/hadoop/.ssh/known_hosts.  You will need to explicitly load HostKeys (cnopts.hostkeys.load(filename)) or disableHostKey checking (cnopts.hostkeys = None).
  warnings.warn(wmsg, UserWarning)
put: `/cerc/': No such file or directory

real    0m3.248s
user    0m5.199s
sys    0m0.347s
put: `/cerc/': No such file or directory

real    0m3.386s
user    0m5.575s
sys    0m0.345s
put: `/cerc/': No such file or directory

real    0m3.513s
user    0m5.731s
sys    0m0.327s
put: `/cerc/': No such file or directory

real    0m3.481s
user    0m5.735s
sys    0m0.390s
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
 

Os arquivo completos de log do EMR contidos nos arquivos stderr e stdout estão anexados nesse defeito para análise se necessário;

stderr - Arquivo "Bug_DAG não está falhando quando temos um erro no HDFS_Arquivo_stderr.txt"

stdout - Arquivo "Bug_DAG não está falhando quando temos um erro no HDFS_Arquivo_stdout.txt"

Parte do código que temos essa validação:

  echo "Movendo os arquivos para o hdfs" && echo "" && echo "Movendo URs"
  time find ur.parquet -name "part-*.parquet" | xargs -n$qtd_arquivos -P $(nproc) bash -c 'hdfs dfs -mkdir -p /cerc/${1%/*};hdfs dfs -put -f $@  /cerc/${1%/*}' bash
  echo "" && echo "Movendo ERROs"
  time find erros.parquet -name "part-*.parquet" | xargs -n$qtd_arquivos -P $(nproc) bash -c 'hdfs dfs -mkdir -p /cerc/${1%/*};hdfs dfs -put -f $@  /cerc/${1%/*}' bash
  echo "" && echo "Movendo CONTRATOs"
  time find contrato.parquet -name "part-*.parquet" | xargs -n$qtd_arquivos -P $(nproc) bash -c 'hdfs dfs -mkdir -p /cerc/${1%/*};hdfs dfs -put -f $@  /cerc/${1%/*}' bash
  echo "" && echo "Movendo RELACOEs"
  time find relacao_ur_contrato.parquet -name "part-*.parquet" | xargs -n$qtd_arquivos -P $(nproc) bash -c 'hdfs dfs -mkdir -p /cerc/${1%/*};hdfs dfs -put -f $@  /cerc/${1%/*}' bash
  echo "Arquivos enviado para o hdfs"

Resultado Esperado:

O processamento identifica um erro relacionado ao HDFS (como esperado), loga o erro no arquivo de log stderr e já encerra a sua execução do fluxo, falhando nesse momento já a DAG também.
